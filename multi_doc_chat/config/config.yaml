embedding_model:
  provider: "huggingface"
  model_name: "sentence-transformers/all-MiniLM-L6-v2"  # Fast, open-source; swap for others like "BAAI/bge-large-en-v1.5" if needed

retriever:
  top_k: 10
  search_type: "mmr"
# Options: "similarity", "mmr", "similarity_score_threshold"
  # MMR (Maximal Marginal Relevance) parameters for diverse results
  fetch_k: 20
# Number of documents to fetch before MMR re-ranking (should be > top_k)
  lambda_mult: 0.5  # Balances relevance (1.0) vs. diversity (0.0)  (0=max diversity, 1=max relevance)


llm:
  google:
    provider: "google"
    model_name: "gemini-2.5-flash"
    temperature: 0
    max_output_tokens: 2048